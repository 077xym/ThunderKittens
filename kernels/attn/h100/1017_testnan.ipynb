{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import thunderkittens as tk\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"You are using `torch.load` with `weights_only=False`\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = \"/home/bfs/simran/attention/nanoGPT-TK/\"\n",
    "files = os.listdir(fpath)\n",
    "files = [f for f in files if f.endswith(\".pt\")]\n",
    "\n",
    "files1 = [f for f in files if \"1\" in f]\n",
    "files2 = [f for f in files if \"2\" in f]\n",
    "files3 = [f for f in files if \"3\" in f]\n",
    "files4 = [f for f in files if \"4\" in f]\n",
    "files5 = [f for f in files if \"5\" in f]\n",
    "files6 = [f for f in files if \"6\" in f]\n",
    "files7 = [f for f in files if \"7\" in f]\n",
    "files8 = [f for f in files if \"8\" in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1q.pt', '1k.pt', '1v.pt', '1o.pt']\n",
      "tensor(False, device='cuda:0') tensor(False, device='cuda:0') tensor(False, device='cuda:0')\n",
      "NANs in output: tensor(False, device='cuda:0')\n",
      "q shape:  torch.Size([12, 12, 768, 64])\n",
      "k shape:  torch.Size([12, 12, 768, 64])\n",
      "v shape:  torch.Size([12, 12, 768, 64])\n",
      "o shape:  torch.Size([12, 12, 768, 64])\n",
      "outputs shape:  torch.Size([12, 12, 768, 64])\n",
      "l_vec shape:  torch.Size([12, 12, 768, 1])\n",
      "mean tensor(2.8849e-05, device='cuda:0', dtype=torch.bfloat16)\n",
      "['2q.pt', '2k.pt', '2v.pt', '2o.pt']\n",
      "tensor(False, device='cuda:0') tensor(False, device='cuda:0') tensor(False, device='cuda:0')\n",
      "NANs in output: tensor(False, device='cuda:0')\n",
      "q shape:  torch.Size([12, 12, 768, 64])\n",
      "k shape:  torch.Size([12, 12, 768, 64])\n",
      "v shape:  torch.Size([12, 12, 768, 64])\n",
      "o shape:  torch.Size([12, 12, 768, 64])\n",
      "outputs shape:  torch.Size([12, 12, 768, 64])\n",
      "l_vec shape:  torch.Size([12, 12, 768, 1])\n",
      "mean tensor(2.8849e-05, device='cuda:0', dtype=torch.bfloat16)\n",
      "['3q.pt', '3k.pt', '3v.pt', '3o.pt']\n",
      "tensor(False, device='cuda:0') tensor(False, device='cuda:0') tensor(False, device='cuda:0')\n",
      "NANs in output: tensor(False, device='cuda:0')\n",
      "q shape:  torch.Size([12, 12, 768, 64])\n",
      "k shape:  torch.Size([12, 12, 768, 64])\n",
      "v shape:  torch.Size([12, 12, 768, 64])\n",
      "o shape:  torch.Size([12, 12, 768, 64])\n",
      "outputs shape:  torch.Size([12, 12, 768, 64])\n",
      "l_vec shape:  torch.Size([12, 12, 768, 1])\n",
      "mean tensor(1.3411e-05, device='cuda:0', dtype=torch.bfloat16)\n",
      "['4q.pt', '4k.pt', '4v.pt', '4o.pt']\n",
      "tensor(False, device='cuda:0') tensor(False, device='cuda:0') tensor(False, device='cuda:0')\n",
      "NANs in output: tensor(False, device='cuda:0')\n",
      "q shape:  torch.Size([12, 12, 768, 64])\n",
      "k shape:  torch.Size([12, 12, 768, 64])\n",
      "v shape:  torch.Size([12, 12, 768, 64])\n",
      "o shape:  torch.Size([12, 12, 768, 64])\n",
      "outputs shape:  torch.Size([12, 12, 768, 64])\n",
      "l_vec shape:  torch.Size([12, 12, 768, 1])\n",
      "mean tensor(2.6822e-05, device='cuda:0', dtype=torch.bfloat16)\n",
      "['5q.pt', '5k.pt', '5v.pt', '5o.pt']\n",
      "tensor(False, device='cuda:0') tensor(False, device='cuda:0') tensor(False, device='cuda:0')\n",
      "NANs in output: tensor(False, device='cuda:0')\n",
      "q shape:  torch.Size([12, 12, 768, 64])\n",
      "k shape:  torch.Size([12, 12, 768, 64])\n",
      "v shape:  torch.Size([12, 12, 768, 64])\n",
      "o shape:  torch.Size([12, 12, 768, 64])\n",
      "outputs shape:  torch.Size([12, 12, 768, 64])\n",
      "l_vec shape:  torch.Size([12, 12, 768, 1])\n",
      "mean tensor(2.6584e-05, device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<MeanBackward0>)\n",
      "['6q.pt', '6k.pt', '6v.pt', '6o.pt']\n",
      "tensor(False, device='cuda:0') tensor(False, device='cuda:0') tensor(False, device='cuda:0')\n",
      "NANs in output: tensor(False, device='cuda:0')\n",
      "q shape:  torch.Size([12, 12, 768, 64])\n",
      "k shape:  torch.Size([12, 12, 768, 64])\n",
      "v shape:  torch.Size([12, 12, 768, 64])\n",
      "o shape:  torch.Size([12, 12, 768, 64])\n",
      "outputs shape:  torch.Size([12, 12, 768, 64])\n",
      "l_vec shape:  torch.Size([12, 12, 768, 1])\n",
      "mean tensor(2.4080e-05, device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<MeanBackward0>)\n",
      "['7q.pt', '7k.pt', '7v.pt', '7o.pt']\n",
      "tensor(False, device='cuda:0') tensor(False, device='cuda:0') tensor(False, device='cuda:0')\n",
      "NANs in output: tensor(False, device='cuda:0')\n",
      "q shape:  torch.Size([12, 12, 768, 64])\n",
      "k shape:  torch.Size([12, 12, 768, 64])\n",
      "v shape:  torch.Size([12, 12, 768, 64])\n",
      "o shape:  torch.Size([12, 12, 768, 64])\n",
      "outputs shape:  torch.Size([12, 12, 768, 64])\n",
      "l_vec shape:  torch.Size([12, 12, 768, 1])\n",
      "mean tensor(2.6107e-05, device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<MeanBackward0>)\n",
      "['8q.pt', '8k.pt', '8v.pt', '8o.pt']\n",
      "tensor(False, device='cuda:0') tensor(False, device='cuda:0') tensor(False, device='cuda:0')\n",
      "NANs in output: tensor(False, device='cuda:0')\n",
      "q shape:  torch.Size([12, 12, 768, 64])\n",
      "k shape:  torch.Size([12, 12, 768, 64])\n",
      "v shape:  torch.Size([12, 12, 768, 64])\n",
      "o shape:  torch.Size([12, 12, 768, 64])\n",
      "outputs shape:  torch.Size([12, 12, 768, 64])\n",
      "l_vec shape:  torch.Size([12, 12, 768, 1])\n",
      "mean tensor(2.4199e-05, device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "\n",
    "def dump_tensors_to_file(q, k, v, o, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        tensors = [q, k, v, o]\n",
    "        flattened = [t.to(torch.float32).flatten().detach().cpu().numpy() for t in tensors]\n",
    "        \n",
    "        for tensor in flattened:\n",
    "            for i in trange(len(tensor)):\n",
    "                f.write(repr(float(tensor[i])))\n",
    "                f.write(' ')\n",
    "\n",
    "def process_tensor_set(q, k, v, o, set_name):\n",
    "    filename = f'tensors_{set_name}.txt'\n",
    "    dump_tensors_to_file(q, k, v, o, filename)\n",
    "    print(f\"Tensors for set {set_name} dumped to {filename}\")\n",
    "    \n",
    "def run_attn(q, k, v, o, l_vec):\n",
    "    tk.mha_forward(q, k, v, o, l_vec, True) \n",
    "    torch.cuda.synchronize()\n",
    "    return o\n",
    "\n",
    "for idx, fs in enumerate([files1, files2, files3, files4, files5, files6, files7, files8], 1):\n",
    "    print(fs)\n",
    "    q_path = [f for f in fs if \"q\" in f][0]\n",
    "    k_path = [f for f in fs if \"k\" in f][0]\n",
    "    v_path = [f for f in fs if \"v\" in f][0]\n",
    "    o_path = [f for f in fs if \"o\" in f][0]\n",
    "    q = torch.load(fpath + q_path, weights_only=True)\n",
    "    k = torch.load(fpath + k_path, weights_only=True)\n",
    "    v = torch.load(fpath + v_path, weights_only=True)\n",
    "    o = torch.load(fpath + o_path, weights_only=True)\n",
    "\n",
    "    # are there nans in the q, k, v tensors?\n",
    "    print(torch.isnan(q).any(), torch.isnan(k).any(), torch.isnan(v).any())\n",
    "\n",
    "    # sanity check with randn instead of above q, k, v\n",
    "    # q = torch.randn_like(q, dtype=torch.bfloat16, device='cuda')\n",
    "    # k = torch.randn_like(k, dtype=torch.bfloat16, device='cuda')\n",
    "    # v = torch.randn_like(v, dtype=torch.bfloat16, device='cuda')\n",
    "\n",
    "    b, h, n, d = q.shape\n",
    "    # print(q.shape, k.shape, v.shape, o.shape)\n",
    "    outputs = torch.empty((b, h, n, d), dtype=torch.bfloat16, device='cuda')\n",
    "    l_vec   = torch.empty((b, h, n, 1), dtype=torch.float32, device='cuda')\n",
    "    \n",
    "    run_attn(q, k, v, outputs, l_vec)\n",
    "    ref_o = torch.nn.functional.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=0.0, is_causal=True)\n",
    "\n",
    "    ################ CHECKS ################\n",
    "    # are there nans?\n",
    "    print('NANs in output:', torch.isnan(outputs).any())\n",
    "\n",
    "    # compare outputs (computed here) and o (saved during training)?\n",
    "    # print(outputs.shape, o.shape)\n",
    "    max_diff = torch.mean(torch.abs(outputs - ref_o))\n",
    "    \n",
    "    # process_tensor_set(q, k, v, outputs, f'set_{idx}')\n",
    "    # print shapes\n",
    "    print(\"q shape: \", q.shape)\n",
    "    print(\"k shape: \", k.shape)\n",
    "    print(\"v shape: \", v.shape)\n",
    "    print(\"o shape: \", o.shape)\n",
    "    print(\"outputs shape: \", outputs.shape)\n",
    "    print(\"l_vec shape: \", l_vec.shape)\n",
    "    print('mean', max_diff)\n",
    "    breakpoint()\n",
    "    \n",
    "    # where are the non-zeros in the tensor?\n",
    "    # print(torch.isnan(outputs).nonzero())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True, device='cuda:0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.isnan(outputs).any()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sim2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
