{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q.shape=torch.Size([1, 1, 2048, 1, 256]), k.shape=torch.Size([1, 1, 2048, 1, 256]), v.shape=torch.Size([1, 1, 2048, 64, 1])\n",
      "kv_state.shape=torch.Size([1, 1, 2048, 64, 256]), out.shape=torch.Size([1, 1, 2048, 64])\n"
     ]
    }
   ],
   "source": [
    "B = 1\n",
    "H = 1\n",
    "N = 2048\n",
    "D = 256\n",
    "DV = 64\n",
    "\n",
    "Q = (torch.ones(B*H*N*D, dtype=torch.bfloat16, device='cuda').reshape(B, H, N, D)).to(torch.float32)/(D*DV)\n",
    "K = (torch.arange(B*H*N*D, dtype=torch.bfloat16, device='cuda').reshape(B, H, N, D)).to(torch.float32)/(D*DV*2)\n",
    "V = (torch.ones(B*H*N*DV, dtype=torch.bfloat16, device='cuda').reshape(B, H, N, DV)).to(torch.float32)\n",
    "\n",
    "q, k, v = Q.unsqueeze(-2), K.unsqueeze(-2), V.unsqueeze(-1)\n",
    "kv_state = (k * v).cumsum(dim=2)\n",
    "out = (q * kv_state).sum(dim=-1)\n",
    "last_kv = kv_state[:, :, -1]\n",
    "\n",
    "print(f\"{q.shape=}, {k.shape=}, {v.shape=}\")\n",
    "print(f\"{kv_state.shape=}, {out.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[16376.0000, 16383.0000, 16383.0000, 16383.0000, 16383.0000,\n",
       "          16383.0020, 16383.0020, 16383.0020, 16383.0020, 16383.0059,\n",
       "          16383.0059, 16383.0059, 16383.0078, 16383.0078, 16383.0078,\n",
       "          16383.0078, 16383.0078, 16383.0234, 16383.0234, 16383.0234,\n",
       "          16383.0234, 16383.0254, 16383.0254, 16383.0254, 16383.0293,\n",
       "          16383.0293, 16383.0293, 16383.0293, 16383.0312, 16383.0312,\n",
       "          16383.0312, 16383.0312, 16383.0312, 16383.0938, 16383.0938,\n",
       "          16383.0938, 16383.0938, 16383.0957, 16383.0957, 16383.0957,\n",
       "          16383.0957, 16383.0996, 16383.0996, 16383.0996, 16383.1016,\n",
       "          16383.1016, 16383.1016, 16383.1016, 16383.1172, 16383.1172,\n",
       "          16383.1172, 16383.1172, 16383.1172, 16383.1191, 16383.1191,\n",
       "          16383.1191, 16383.1230, 16383.1230, 16383.1230, 16383.1230,\n",
       "          16383.1250, 16383.1250, 16383.1250, 16383.1250, 16383.1250,\n",
       "          16383.3750, 16383.3750, 16383.3750, 16383.3750, 16383.3770,\n",
       "          16383.3770, 16383.3770, 16383.3770, 16383.3809, 16383.3809,\n",
       "          16383.3809, 16383.3828, 16383.3828, 16383.3828, 16383.3828,\n",
       "          16383.3828, 16383.3984, 16383.3984, 16383.3984, 16383.3984,\n",
       "          16383.4004, 16383.4004, 16383.4004, 16383.4043, 16383.4043,\n",
       "          16383.4043, 16383.4043, 16383.4062, 16383.4062, 16383.4062,\n",
       "          16383.4062, 16383.4688, 16383.4688, 16383.4688, 16383.4688,\n",
       "          16383.4688, 16383.4707, 16383.4707, 16383.4707, 16383.4707,\n",
       "          16383.4746, 16383.4746, 16383.4746, 16383.4766, 16383.4766,\n",
       "          16383.4766, 16383.4766, 16383.4922, 16383.4922, 16383.4922,\n",
       "          16383.4922, 16383.4922, 16383.4941, 16383.4941, 16383.4941,\n",
       "          16383.4980, 16383.4980, 16383.4980, 16383.4980, 16383.5000,\n",
       "          16383.5000, 16383.5000, 16383.5000, 16384.0000, 16384.5000,\n",
       "          16384.5000, 16384.5000, 16384.5000, 16384.5020, 16384.5020,\n",
       "          16384.5020, 16384.5020, 16384.5059, 16384.5059, 16384.5059,\n",
       "          16384.5078, 16384.5078, 16384.5078, 16384.5078, 16384.5078,\n",
       "          16384.5234, 16384.5234, 16384.5234, 16384.5234, 16384.5254,\n",
       "          16384.5254, 16384.5254, 16384.5293, 16384.5293, 16384.5293,\n",
       "          16384.5293, 16384.5312, 16384.5312, 16384.5312, 16384.5312,\n",
       "          16384.5312, 16384.5938, 16384.5938, 16384.5938, 16384.5938,\n",
       "          16384.5957, 16384.5957, 16384.5957, 16384.5957, 16384.5996,\n",
       "          16384.5996, 16384.5996, 16384.6016, 16384.6016, 16384.6016,\n",
       "          16384.6016, 16384.6172, 16384.6172, 16384.6172, 16384.6172,\n",
       "          16384.6172, 16384.6191, 16384.6191, 16384.6191, 16384.6230,\n",
       "          16384.6230, 16384.6230, 16384.6230, 16384.6250, 16384.6250,\n",
       "          16384.6250, 16384.6250, 16384.8750, 16384.8750, 16384.8750,\n",
       "          16384.8750, 16384.8750, 16384.8770, 16384.8770, 16384.8770,\n",
       "          16384.8770, 16384.8809, 16384.8809, 16384.8809, 16384.8828,\n",
       "          16384.8828, 16384.8828, 16384.8828, 16384.8828, 16384.8984,\n",
       "          16384.8984, 16384.8984, 16384.8984, 16384.9004, 16384.9004,\n",
       "          16384.9004, 16384.9043, 16384.9043, 16384.9043, 16384.9043,\n",
       "          16384.9062, 16384.9062, 16384.9062, 16384.9062, 16384.9688,\n",
       "          16384.9688, 16384.9688, 16384.9688, 16384.9688, 16384.9707,\n",
       "          16384.9707, 16384.9707, 16384.9707, 16384.9746, 16384.9746,\n",
       "          16384.9746, 16384.9766, 16384.9766, 16384.9766, 16384.9766,\n",
       "          16384.9922, 16384.9922, 16384.9922, 16384.9922, 16384.9922,\n",
       "          16384.9941, 16384.9941, 16384.9941, 16384.9980, 16384.9980,\n",
       "          16384.9980, 16384.9980, 16385.0000, 16385.0000, 16385.0000,\n",
       "          16385.0000]]], device='cuda:0')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_kv[:, :, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape=torch.Size([1, 1, 2048, 2048])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 2048, 64])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pytorch_test(Q, K, V, TESTNAME='all'):\n",
    "\n",
    "    def make_causal(X):\n",
    "        (b,h,n,m) = X.shape\n",
    "        print(f\"{X.shape=}\")\n",
    "        mask= ~(torch.arange(n).view(1,1,n,1) >= torch.arange(n).view(1,1,1,n)).expand(b,h,n,n)\n",
    "        X[mask] = 0.\n",
    "        return X\n",
    "\n",
    "    ATT = make_causal(torch.einsum(\"bhnd,bhmd->bhnm\", Q, K))\n",
    "    out = torch.einsum(\"bhnm,bhmd->bhnd\", ATT, V).to(torch.bfloat16)\n",
    "    return out\n",
    "\n",
    "o = pytorch_test(Q, K, V)\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000e+00, 1.2666e-06, 2.5332e-06, 3.7998e-06, 5.0664e-06, 6.3181e-06,\n",
      "        7.5996e-06, 8.8215e-06, 1.0133e-05, 1.1384e-05, 1.2636e-05, 1.3888e-05,\n",
      "        1.5199e-05, 1.6451e-05, 1.7643e-05, 1.8954e-05, 2.0266e-05, 2.1458e-05,\n",
      "        2.2769e-05, 2.3961e-05, 2.5272e-05, 2.6584e-05, 2.7776e-05, 2.9087e-05,\n",
      "        3.0398e-05, 3.1710e-05, 3.2902e-05, 3.4094e-05, 3.5286e-05, 3.6716e-05,\n",
      "        3.7909e-05, 3.9101e-05, 4.0531e-05, 4.1723e-05, 4.2915e-05, 4.4346e-05,\n",
      "        4.5538e-05, 4.6730e-05, 4.7922e-05, 4.9353e-05, 5.0545e-05, 5.1737e-05,\n",
      "        5.3167e-05, 5.4359e-05, 5.5552e-05, 5.6982e-05, 5.8174e-05, 5.9366e-05,\n",
      "        6.0797e-05, 6.1989e-05, 6.3419e-05, 6.4373e-05, 6.5804e-05, 6.7234e-05,\n",
      "        6.8188e-05, 6.9618e-05, 7.0572e-05, 7.2002e-05, 7.3433e-05, 7.4387e-05,\n",
      "        7.5817e-05, 7.7248e-05, 7.8201e-05, 7.9632e-05], device='cuda:0',\n",
      "       dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "print(o[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TK outputs: note refresh the printouts folder if you're seeing strange results\n",
    "import os\n",
    "\n",
    "path = \"printouts\"\n",
    "os.listdir(path)\n",
    "\n",
    "# load o.txt\n",
    "with open(f\"{path}/o.txt\", \"r\") as f:\n",
    "    o_tk = torch.tensor([float(x) for x in f.read().split()]).reshape(1, 1, 2048, 64)\n",
    "# load o_ref.txt\n",
    "with open(f\"{path}/o_ref.txt\", \"r\") as f:\n",
    "    o_ref_tk = torch.tensor([float(x) for x in f.read().split()]).reshape(1, 1, 2048, 64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 2048, 64])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.0000e+00, 1.2666e-06, 2.5332e-06, 3.7998e-06, 5.0664e-06, 6.3181e-06,\n",
       "        7.5996e-06, 8.8215e-06, 1.0133e-05, 1.1384e-05, 1.2636e-05, 1.3888e-05,\n",
       "        1.5199e-05, 1.6451e-05, 1.7643e-05, 1.8954e-05, 2.0266e-05, 2.1458e-05,\n",
       "        2.2769e-05, 2.3961e-05, 2.5272e-05, 2.6584e-05, 2.7776e-05, 2.9087e-05,\n",
       "        3.0398e-05, 3.1710e-05, 3.2902e-05, 3.4094e-05, 3.5286e-05, 3.6717e-05,\n",
       "        3.7909e-05, 3.9101e-05, 4.0531e-05, 4.1723e-05, 4.2915e-05, 4.4346e-05,\n",
       "        4.5538e-05, 4.6730e-05, 4.7922e-05, 4.9353e-05, 5.0545e-05, 5.1737e-05,\n",
       "        5.3167e-05, 5.4359e-05, 5.5551e-05, 5.6982e-05, 5.8174e-05, 5.9366e-05,\n",
       "        6.0797e-05, 6.1989e-05, 6.3419e-05, 6.4373e-05, 6.5803e-05, 6.7234e-05,\n",
       "        6.8188e-05, 6.9618e-05, 7.0572e-05, 7.2002e-05, 7.3433e-05, 7.4387e-05,\n",
       "        7.5817e-05, 7.7248e-05, 7.8201e-05, 7.9632e-05])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(o_ref_tk.shape)\n",
    "o_ref_tk[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 2048, 64])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.0000e+00, 1.2666e-06, 2.5332e-06, 3.7998e-06, 5.0664e-06, 6.3181e-06,\n",
       "        7.5996e-06, 8.8811e-06, 1.0133e-05, 1.1384e-05, 1.2636e-05, 1.3947e-05,\n",
       "        1.5199e-05, 1.6451e-05, 1.7762e-05, 1.8954e-05, 2.0266e-05, 2.1577e-05,\n",
       "        2.2769e-05, 2.4080e-05, 2.5272e-05, 2.6584e-05, 2.7895e-05, 2.9087e-05,\n",
       "        3.0398e-05, 3.1710e-05, 3.2902e-05, 3.4094e-05, 3.5524e-05, 3.6717e-05,\n",
       "        3.7909e-05, 3.9339e-05, 4.0531e-05, 4.1723e-05, 4.3154e-05, 4.4346e-05,\n",
       "        4.5538e-05, 4.6969e-05, 4.8161e-05, 4.9353e-05, 5.0545e-05, 5.1975e-05,\n",
       "        5.3167e-05, 5.4359e-05, 5.5790e-05, 5.6982e-05, 5.8174e-05, 5.9605e-05,\n",
       "        6.0797e-05, 6.1989e-05, 6.3419e-05, 6.4373e-05, 6.5803e-05, 6.7234e-05,\n",
       "        6.8188e-05, 6.9618e-05, 7.1049e-05, 7.2002e-05, 7.3433e-05, 7.4863e-05,\n",
       "        7.5817e-05, 7.7248e-05, 7.8678e-05, 7.9632e-05])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(o_tk.shape)\n",
    "o_tk[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = \"arange.txt\"\n",
    "with open(fpath, \"r\") as f:\n",
    "    arange_tensor = [float(x) for x in f.read().split()]\n",
    "\n",
    "num_q_elements = B*H*N*D\n",
    "num_k_elements = B*H*N*D\n",
    "num_v_elements = B*H*N*DV\n",
    "num_o_elements = B*H*N*DV\n",
    "\n",
    "q_in = torch.tensor(arange_tensor[:num_q_elements]).reshape(B, H, N, D)\n",
    "k_in = torch.tensor(arange_tensor[num_q_elements:num_q_elements+num_k_elements]).reshape(B, H, N, D)\n",
    "v_in = torch.tensor(arange_tensor[num_q_elements+num_k_elements:num_q_elements+num_k_elements+num_v_elements]).reshape(B, H, N, DV)\n",
    "o_in = torch.tensor(arange_tensor[num_q_elements+num_k_elements+num_v_elements:num_q_elements+num_k_elements+num_v_elements+num_o_elements]).reshape(B, H, N, DV)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000e+00, 1.2666e-06, 2.5332e-06, 3.7998e-06, 5.0664e-06, 6.3181e-06,\n",
       "        7.5996e-06, 8.8215e-06, 1.0133e-05, 1.1384e-05, 1.2636e-05, 1.3888e-05,\n",
       "        1.5199e-05, 1.6451e-05, 1.7643e-05, 1.8954e-05, 2.0266e-05, 2.1458e-05,\n",
       "        2.2769e-05, 2.3961e-05, 2.5272e-05, 2.6584e-05, 2.7776e-05, 2.9087e-05,\n",
       "        3.0398e-05, 3.1710e-05, 3.2902e-05, 3.4094e-05, 3.5286e-05, 3.6716e-05,\n",
       "        3.7909e-05, 3.9101e-05, 4.0531e-05, 4.1723e-05, 4.2915e-05, 4.4346e-05,\n",
       "        4.5538e-05, 4.6730e-05, 4.7922e-05, 4.9353e-05, 5.0545e-05, 5.1737e-05,\n",
       "        5.3167e-05, 5.4359e-05, 5.5552e-05, 5.6982e-05, 5.8174e-05, 5.9366e-05,\n",
       "        6.0797e-05, 6.1989e-05, 6.3419e-05, 6.4373e-05, 6.5804e-05, 6.7234e-05,\n",
       "        6.8188e-05, 6.9618e-05, 7.0572e-05, 7.2002e-05, 7.3433e-05, 7.4387e-05,\n",
       "        7.5817e-05, 7.7248e-05, 7.8201e-05, 7.9632e-05])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o_in[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000e+00, 1.2666e-06, 2.5332e-06, 3.7998e-06, 5.0664e-06, 6.3181e-06,\n",
       "        7.5996e-06, 8.8215e-06, 1.0133e-05, 1.1384e-05, 1.2636e-05, 1.3888e-05,\n",
       "        1.5199e-05, 1.6451e-05, 1.7643e-05, 1.8954e-05, 2.0266e-05, 2.1458e-05,\n",
       "        2.2769e-05, 2.3961e-05, 2.5272e-05, 2.6584e-05, 2.7776e-05, 2.9087e-05,\n",
       "        3.0398e-05, 3.1710e-05, 3.2902e-05, 3.4094e-05, 3.5286e-05, 3.6716e-05,\n",
       "        3.7909e-05, 3.9101e-05, 4.0531e-05, 4.1723e-05, 4.2915e-05, 4.4346e-05,\n",
       "        4.5538e-05, 4.6730e-05, 4.7922e-05, 4.9353e-05, 5.0545e-05, 5.1737e-05,\n",
       "        5.3167e-05, 5.4359e-05, 5.5552e-05, 5.6982e-05, 5.8174e-05, 5.9366e-05,\n",
       "        6.0797e-05, 6.1989e-05, 6.3419e-05, 6.4373e-05, 6.5804e-05, 6.7234e-05,\n",
       "        6.8188e-05, 6.9618e-05, 7.0572e-05, 7.2002e-05, 7.3433e-05, 7.4387e-05,\n",
       "        7.5817e-05, 7.7248e-05, 7.8201e-05, 7.9632e-05], device='cuda:0',\n",
       "       dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "based",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
